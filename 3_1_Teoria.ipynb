{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3.1.-Teoria.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aszapla/Curso-DL/blob/master/3_1_Teoria.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5cNF2JaztC9",
        "colab_type": "text"
      },
      "source": [
        "# Sesión 3.1: redes recurrentes avanzadas\n",
        "\n",
        "Profesor: [Jorge Calvo Zaragoza](mailto:jcalvo@prhlt.upv.es)\n",
        "\n",
        "## Resumen\n",
        "En esta sesión:\n",
        "  * Repasaremos arquitecturas neuronales avanzadas con redes recurrentes.\n",
        "  * Veremos problemas complejos que utilizan estas estructuras. \n",
        "  * Programaremos paso a paso un traductor automático."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsbXE-xaz6yZ",
        "colab_type": "text"
      },
      "source": [
        "## Introducción\n",
        "\n",
        "Dependiendo de la tipología de las entradas y las salidas, podemos formular diferentes escenarios de aprendizaje automático:\n",
        "\n",
        "![Redes recurrentes](https://www.microsoft.com/en-us/cognitive-toolkit/wp-content/uploads/sites/3/2017/04/071316_1312_RecurrentNe3.jpg)\n",
        "\n",
        "* **One to one**: clasificación convencional en el cual a una entrada le corresponde una salida.\n",
        "* **One to many**: tareas en las cuáles se quiere obtener una secuencia a partir de una única entrada. Ejemplo: descripción automática de imagen.\n",
        "* **Many to one**: clasificación de secuencias, en las cuales queremos asignar una categoria a una secuencia. Ejemplo: análisis de sentimiento.\n",
        "* **Many to many**: tareas en las cuales tanto la entrada como la salida son secuencias. Se puede plantear de diferente forma dependiendo de si las secuencias son desacopladas (traducción automática) o si hay una fuerte relación entre cada elemento de la entrada y la salida (etiquetado gramatical).\n",
        "\n",
        "Ya se ha visto en la anterior sesión que las redes recurrentes son adecuadas para tratar con problemas de naturaleza secuencial. Keras contiene la implementación tres tipos de redes recurrentes, añadiendo una interfaz para desarrollar redes recurrentes a medida:\n",
        "\n",
        "* **[SimpleRNN](https://keras.io/layers/recurrent/#simplernn)**\n",
        "* **[LSTM](https://keras.io/layers/recurrent/#lstm)**\n",
        "* **[GRU](https://keras.io/layers/recurrent/#gru)**\n",
        "\n",
        "![texto alternativo](http://sqlml.azurewebsites.net/wp-content/uploads/2017/11/null-9.png)\n",
        "\n",
        "La flexibilidad para construir las distintas topologías mostradas en la figura anterior se proporcionan a través de siguientes parámetros:\n",
        "\n",
        "* **return_sequences**: cuando está desactivado, sólo devuelve la salida del último instante de tiempo (many to one); cuando está activado, devuelve la salida de todos los instantes (many to many).\n",
        "* **return_state**: indica si se accede a los estados recurrentes de las neuronas.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcAhTwYSCFYH",
        "colab_type": "code",
        "outputId": "948d92b2-8605-42e9-8a26-e821f7cb667e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "from keras.layers import Input\n",
        "from keras.layers import SimpleRNN, LSTM, GRU\n",
        "\n",
        "# La entrada a una red recurrente tiene dos dimensiones:\n",
        "# - El número de instantes de tiempo (None para indicar que variable)\n",
        "# - Número de características de entrada\n",
        "T = 100\n",
        "feature_dim = 2\n",
        "input_layer = Input(shape=(T, feature_dim))\n",
        "  \n",
        "# LSTM\n",
        "x0 = LSTM(64)(input_layer)\n",
        "x1 = LSTM(64,return_state=True)(input_layer)\n",
        "x2 = LSTM(64,return_sequences=True)(input_layer)\n",
        "x3 = LSTM(64,return_sequences=True,return_state=True)(input_layer)\n",
        "print('LSTM: ' + str(x0))\n",
        "print('LSTM + return_state: ' + str(x1))\n",
        "print('LSTM + return_sequences: ' + str(x2))\n",
        "print('LSTM + return_sequences + return_state: ' + str(x3))\n",
        "print()\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LSTM: Tensor(\"lstm_1/TensorArrayReadV3:0\", shape=(?, 64), dtype=float32)\n",
            "LSTM + return_state: [<tf.Tensor 'lstm_2/TensorArrayReadV3:0' shape=(?, 64) dtype=float32>, <tf.Tensor 'lstm_2/while/Exit_2:0' shape=(?, 64) dtype=float32>, <tf.Tensor 'lstm_2/while/Exit_3:0' shape=(?, 64) dtype=float32>]\n",
            "LSTM + return_sequences: Tensor(\"lstm_3/transpose_1:0\", shape=(?, ?, 64), dtype=float32)\n",
            "LSTM + return_sequences + return_state: [<tf.Tensor 'lstm_4/transpose_1:0' shape=(?, ?, 64) dtype=float32>, <tf.Tensor 'lstm_4/while/Exit_2:0' shape=(?, 64) dtype=float32>, <tf.Tensor 'lstm_4/while/Exit_3:0' shape=(?, 64) dtype=float32>]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dr7OUFFC93e_",
        "colab_type": "text"
      },
      "source": [
        "Como veremos a continuación, la posibilidad de obtener los estados internos de la red recurrente es lo que nos permite construir una arquitectura secuencia a secuencia desacoplada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSsopV-kNhyY",
        "colab_type": "text"
      },
      "source": [
        "#### Recurrencia bidireccional\n",
        "\n",
        "En la mayoría de tareas, es interesante tener no sólo el contexto anterior sino también el posterior a la hora de predecir un elemento en un instante dado. En tal caso, podemos establecer una **recurrencia bidireccional**, en las cuales una neurona tiene dos conexiones recurrentes que, **a la hora de desplegarse**, lo hacen en direcciones opuestas.\n",
        "\n",
        "![texto alternativo](https://cdn-images-1.medium.com/max/764/1*6QnPUSv_t9BY9Fv8_aLb-Q.png)\n",
        "\n",
        "Para implementar redes bidireccionales Keras aporta un *wrapper* que acepta como parámetro un objeto que implemente la super clase recurrente:\n",
        "\n",
        "* [keras.layers.Bidirectional](https://keras.io/layers/wrappers/#bidirectional)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfgdsQ87RPav",
        "colab_type": "code",
        "outputId": "099b679f-20e0-4a06-9728-74e92dfcdf3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "from keras.layers import Input\n",
        "from keras.layers import LSTM, Bidirectional\n",
        "\n",
        "T = None\n",
        "feature_dim = 2\n",
        "\n",
        "# BLSTM\n",
        "input_layer = Input(shape=(T, feature_dim))\n",
        "x0 = Bidirectional(LSTM(64))(input_layer)\n",
        "x1 = Bidirectional(LSTM(64,return_state=True))(input_layer)\n",
        "x2 = Bidirectional(LSTM(64,return_sequences=True))(input_layer)\n",
        "x3 = Bidirectional(LSTM(64,return_sequences=True,return_state=True))(input_layer)\n",
        "\n",
        "print('BLSTM: ' + str(x0))\n",
        "print('BLSTM + return_state: ' + str(x1))\n",
        "print('BLSTM + return_sequences: ' + str(x2))\n",
        "print('BLSTM + return_sequences + return_state: ' + str(x3))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "BLSTM: Tensor(\"bidirectional_1/concat:0\", shape=(?, 128), dtype=float32)\n",
            "BLSTM + return_state: [<tf.Tensor 'bidirectional_2/concat:0' shape=(?, 128) dtype=float32>, <tf.Tensor 'bidirectional_2/while/Exit_2:0' shape=(?, 64) dtype=float32>, <tf.Tensor 'bidirectional_2/while/Exit_3:0' shape=(?, 64) dtype=float32>, <tf.Tensor 'bidirectional_2/while_1/Exit_2:0' shape=(?, 64) dtype=float32>, <tf.Tensor 'bidirectional_2/while_1/Exit_3:0' shape=(?, 64) dtype=float32>]\n",
            "BLSTM + return_sequences: Tensor(\"bidirectional_3/concat:0\", shape=(?, ?, 128), dtype=float32)\n",
            "BLSTM + return_sequences + return_state: [<tf.Tensor 'bidirectional_4/concat:0' shape=(?, ?, 128) dtype=float32>, <tf.Tensor 'bidirectional_4/while/Exit_2:0' shape=(?, 64) dtype=float32>, <tf.Tensor 'bidirectional_4/while/Exit_3:0' shape=(?, 64) dtype=float32>, <tf.Tensor 'bidirectional_4/while_1/Exit_2:0' shape=(?, 64) dtype=float32>, <tf.Tensor 'bidirectional_4/while_1/Exit_3:0' shape=(?, 64) dtype=float32>]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j03Y0Nnd1Am-",
        "colab_type": "text"
      },
      "source": [
        "## Arquitectura secuencia a secuencia\n",
        "\n",
        "De entre todos los enfoques mostrados en el bloque anterior, el más flexible es el de secuencia a secuencia desacoplado (*sequence to sequence*, o *seq2seq*). Típicamente, se implementa con una arquitectura encoder-decoder:\n",
        "\n",
        "![texto alternativo](https://docs.google.com/uc?id=1poBXbaLFiEN0IPZtR0IIbySEnSLGRvih)\n",
        "\n",
        "Esta arquitectura cuenta con dos redes neuronales independientes:\n",
        "* El **encoder** es una red recurrente que se encarga de procesar la entrada elemento a elemento, almacenando en su estado interno una codificación compacta y representativa de la información procesada hasta el momento. Al estado interno de las neuronas del encoder se le llama *context vector* o *thought vector*.\n",
        "* El **decoder** es otra red recurrente que recibe el *context vector* de la última etapa del encoder. En cada paso, predice un elemento del dominio de salida, utilizando el estado interno de la red recurrente y el último elemento predicho. El proceso acaba cuando se emite el elemento especial *EOS* (end of sentence).\n",
        "\n",
        "![texto alternativo](https://devblogs.nvidia.com/wp-content/uploads/2015/06/Figure6_summary_vector_space.png)\n",
        "\n",
        "Esta arquitectura se entrena de manera conjunta, para lo cual tan sólo hacen falta pares de secuencias de entrada y salida, sin necesidad de proporcionar ningun tipo de información acerca de la relación entre los elementos de las mismas.\n",
        "\n",
        "## Ejemplos de tareas\n",
        "\n",
        "Una ventaja de esta arquitectura es que sirve para multitud de tareas que en el pasado se desarrollaban de forma independiente. Aunque cada tarea tiene sus particularidades, esta formulación similar permite que avances significativos en un campo sean generalizables a otro (como veremos más adelante con los modelos de atención).\n",
        "\n",
        "La única restricción para llevar a cabo la mayoría de estas tareas son de índole logístico: ¿tenemos suficientes datos para aprender dicha tarea? ¿tenemos suficiente capacidad computacional para llevar a cabo el entrenamiento? \n",
        "\n",
        "\n",
        "### Modelos de conversación\n",
        "\n",
        "![texto alternativo](https://cdn-images-1.medium.com/max/1585/1*sO-SP58T4brE9EHazHSeGA.png)\n",
        "\n",
        "\n",
        "### Traducción automática\n",
        "\n",
        "![texto alternativo](https://www.wncc-iitb.org/images/semantics.png)\n",
        "\n",
        "\n",
        "### Resumen de texto\n",
        "\n",
        "![texto alternativo](https://cdn-images-1.medium.com/max/1600/1*Cu49wPEpWJPoI0a5AV9Q1Q.png)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYaX8JkL0IVB",
        "colab_type": "text"
      },
      "source": [
        "## Codificación de elementos no numéricos\n",
        "\n",
        "Hemos visto que en los problemas anteriores, los elementos de entrada no son características numéricas (como pasa en el aprendizaje automático clásico o con las redes convolucionales) sino elementos discretos como caracteres o palabras. Si una red neuronal sólo *entiende* de números, ¿cómo podemos indicarle este tipo de características?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JVRsT6n4U0p",
        "colab_type": "text"
      },
      "source": [
        "### One-hot encoding\n",
        "\n",
        "El *one-hot encoding* es una representación numérica de variables discretas. Consiste en asumir vectores de características de dimension igual al número de diferentes valores del conjunto discreto de la variable a codificar. Cada dimension corresponde a un único elemento de dicho conjunto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2eo6i9_1dMx",
        "colab_type": "code",
        "outputId": "516f7f3f-a271-4902-f9e8-5278d1f0c53e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Imaginemos un vocabulario de colores\n",
        "vocabulary = {'rojo', 'amarillo', 'azul', 'verde', 'lila' ,'naranja'}\n",
        "\n",
        "# Asignamos a cada caracter un índice numérico\n",
        "word2int = dict([(char, i) for i, char in enumerate(vocabulary)])\n",
        "print('Asignacion de indice a palabras')\n",
        "print(word2int)\n",
        "\n",
        "# De esta forma las frases se componen de secuencias de vectores de 6 elementos\n",
        "sentence = 'rojo amarillo naranja'\n",
        "tokenized_sentence = sentence.split()\n",
        "encoded_sentence = np.zeros([len(tokenized_sentence),len(vocabulary)])\n",
        "\n",
        "# Para cada palabra, activamos la posición que corresponde a su identificador \n",
        "for i,c in enumerate(sentence.split()):\n",
        "  encoded_sentence[i][ word2int[c] ] = 1\n",
        "\n",
        "# Comprobación\n",
        "print('')\n",
        "print('Frase original: ' + sentence)\n",
        "\n",
        "print('Frase secuencial:')\n",
        "print(str(tokenized_sentence))\n",
        "\n",
        "print('Frase codificada:')\n",
        "print(str(encoded_sentence))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Asignacion de indice a palabras\n",
            "{'azul': 0, 'amarillo': 1, 'rojo': 2, 'naranja': 3, 'verde': 4, 'lila': 5}\n",
            "\n",
            "Frase original: rojo amarillo naranja\n",
            "Frase secuencial:\n",
            "['rojo', 'amarillo', 'naranja']\n",
            "Frase codificada:\n",
            "[[0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcmdgZow43um",
        "colab_type": "text"
      },
      "source": [
        "El one-hot encoding tiene una ventaja importante: no asume ninguna relación entre los elementos del vocabulario. Dicho de otro modo, todos los elementos del conjunto son equidistantes entre sí en la codificación one-hot (distancia hamming 2). Por otra parte, el one-hot encoding tiene la máxima redundancia; en realidad, para codificar N elementos, tan sólo harían falta vectores de log(N) bits.\n",
        "\n",
        "El problema es que si ordenamos cada elemento del vocabulario (por ejemplo, por orden alfabético) y le asignamos su posición codificándola en binario, le estaríamos indicando de alguna forma a la red neuronal que los elementos que están cerca en dicho orden es porque tienen un rol más similar (lo cual no es cierto en la mayoría de las ocasiones).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3xTduU3U4iQ",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "#### Estado actual\n",
        "\n",
        "A menudo encontramos tareas para las cuales el vocabulario a tener en cuenta es inmenso. Por ejemplo, el idioma español tiene alrededor de 100.000 vocablos distintos. Sin embargo, ya hemos comentado que utilizar un enfoque más compacto puede ser perjudicial para el proceso de aprendizaje. Además, ¿qué ocurre con las palabras muy poco frecuentes o que incluso están fuera del vocabulario que habíamos planeado inicialmente? \n",
        "\n",
        "Una posibilidad para lidiar con este escenario es bajar a nivel de caracteres, cuyo vocabulario suele ser mucho más limitado. El problema es que la red neuronal tiene que hacer un esfuerzo mayor en inferir las relaciones entre los distintos elementos de la entrada. En la actualidad, es común utilizar un enfoque intermedio basado en sub-palabras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPGfsWQpaaem",
        "colab_type": "text"
      },
      "source": [
        "#### Keras\n",
        "\n",
        "Keras cuenta con utilidades específicas para tratar con texto y codificaciones one-hot:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hitmWl_QadnC",
        "colab_type": "code",
        "outputId": "80f15a99-2b7c-41e8-ac74-0ac23b49c92f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "\n",
        "# Lista de frases\n",
        "corpus = [\"El rojo y el amarillo hacen naranja.\",\n",
        "     \"El lila viene del azul y del rojo.\",\n",
        "     \"El azul es primario\",\n",
        "     \"El naranja es secundario\"]\n",
        "\n",
        "# Objeto tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "# Ajustamos el objeto al corpus\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "\n",
        "# Comprobación de la asignación de un índice a cada palabra\n",
        "print('Asignacion de indice a palabras')\n",
        "print(tokenizer.word_index)\n",
        "\n",
        "# Comprobamos el número de palabras\n",
        "num_words = len(tokenizer.word_index)\n",
        "print('')\n",
        "print('Número de palabras: ' + str(num_words))\n",
        "\n",
        "# Codificamos una frase\n",
        "sentence = 'rojo amarillo naranja'\n",
        "\n",
        "# La separamos en palabras\n",
        "tokenized_sentence = text_to_word_sequence(sentence)\n",
        "\n",
        "# La codificamos siguiendo one-hot\n",
        "encoded_sentence = tokenizer.texts_to_matrix(tokenized_sentence)\n",
        "\n",
        "# Comprobación\n",
        "print('')\n",
        "print('Frase original: ' + sentence)\n",
        "print('')\n",
        "print('Frase secuencial:')\n",
        "print(str(tokenized_sentence))\n",
        "print('')\n",
        "print('Frase secuencial:')\n",
        "print(str(encoded_sentence))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Asignacion de indice a palabras\n",
            "{'el': 1, 'rojo': 2, 'y': 3, 'naranja': 4, 'del': 5, 'azul': 6, 'es': 7, 'amarillo': 8, 'hacen': 9, 'lila': 10, 'viene': 11, 'primario': 12, 'secundario': 13}\n",
            "\n",
            "Número de palabras: 13\n",
            "\n",
            "Frase original: rojo amarillo naranja\n",
            "\n",
            "Frase secuencial:\n",
            "['rojo', 'amarillo', 'naranja']\n",
            "\n",
            "Frase secuencial:\n",
            "[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoL4M9n76IHl",
        "colab_type": "text"
      },
      "source": [
        "## Embedding\n",
        "\n",
        "Como acabamos de comentar, el one-hot encoding permite al usuario proporcionar a la red una entrada agnóstica, en la cual cada elemento tiene una representación igualmente independiente. Obviamente, para una tarea específica, esta asunción no es valida (ni útil): hay palabras que tienen un rol o un significado similar y por tanto, sería adecuado que tuvieran una representación interna similar. \n",
        "\n",
        "Idealmente, queremos representar cada palabra mediante un vector numérico en el cual las palabras similares (en rol o en significado) esten cerca en ese espacio. Esto se conoce como *embedding*.  Siguiendo los principios del deep learning, queremos que la red aprenda estas relaciones por sí sola en lugar de establecer el embedding siguiendo reglas heurísticas o basadas en nuestra propia intuición. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ng2gvp14cLC4",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "### word2vec\n",
        "\n",
        "La idea de realizar realizar embeddings es muy antigua. Sin embargo, su popularidad se incrementó considerablemente a partir del surgimiento de los modelos *word2vec*.\n",
        "\n",
        "\n",
        "#### Idea \n",
        "\n",
        "![texto alternativo](https://deeplearning4j.org/img/word2vec_diagrams.png)\n",
        "\n",
        "![texto alternativo](http://colah.github.io/posts/2014-07-NLP-RNNs-Representations/img/Bottou-WordSetup.png)\n",
        "\n",
        "#### Análisis\n",
        "\n",
        "![texto alternativo](http://colah.github.io/posts/2014-07-NLP-RNNs-Representations/img/Colbert-WordTable2.png)\n",
        "\n",
        "#### Representación semántica\n",
        "\n",
        "[Visualizacion](http://metaoptimize.s3.amazonaws.com/cw-embeddings-ACL2010/embeddings-mostcommon.EMBEDDING_SIZE=50.png)\n",
        "\n",
        "![texto alternativo](http://colah.github.io/posts/2014-07-NLP-RNNs-Representations/img/Mikolov-GenderVecs.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnJqCinnWvvm",
        "colab_type": "text"
      },
      "source": [
        "### Capas de embedding en Keras\n",
        "\n",
        "En Keras, la capa de embedding no se hace a través de operaciones matemáticas. En su lugar, lo que se hace es acceder a una tabla look-up que asocia cada entero con una posición. La capa Embedding de Keras recibe directamente el entero que identifica un elemento del vocabulario (sin necesidad de hacer un one-hot encoding) y devuelve su representación densa. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrxsgmMTWzyn",
        "colab_type": "code",
        "outputId": "573895be-4765-45f5-f00f-953282c60f74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "import numpy as np\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Embedding\n",
        "\n",
        "# Definimos el tamaño del vocabulario y las dimensiones del espacio latente\n",
        "vocabulary_size = 5\n",
        "embedding_space = 3\n",
        "\n",
        "# Definimos una entrada de longitud variable\n",
        "input_layer = Input(shape=(None,), dtype='int32', name='main_input')\n",
        "\n",
        "# Añadimos la capa de embedding\n",
        "embedded = Embedding(vocabulary_size, embedding_space)(input_layer)\n",
        "\n",
        "# Creamos un modelo a partir de estas dos capas\n",
        "model = Model(input_layer,embedded)\n",
        "\n",
        "# Probamos a 'predecir' a través de esta red \n",
        "integer_encoding = [4,1,3,3,3]\n",
        "output_array = model.predict(np.asarray([integer_encoding]))\n",
        "\n",
        "print('Representación de: ' + str(integer_encoding))\n",
        "print(output_array)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Representación de: [4, 1, 3, 3, 3]\n",
            "[[[-0.01578005  0.03436567 -0.00560244]\n",
            "  [-0.04476501  0.00464042 -0.04337955]\n",
            "  [ 0.02889243 -0.01887957  0.02207902]\n",
            "  [ 0.02889243 -0.01887957  0.02207902]\n",
            "  [ 0.02889243 -0.01887957  0.02207902]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrwD0e6wW0NU",
        "colab_type": "text"
      },
      "source": [
        "A pesar de esta implementación, los valores de esta tabla se aprenden de manera específica para la tarea en cuestión con los medios convencionales de entrenamiento de redes neuronales.\n",
        "\n",
        "A menudo es interesante importar los embeddings obtenidos mediante un word2vec de un dominio similar para utilizarlo como punto de partida en nuestra tarea. Keras facilita este escenario permitiendo establecer los pesos iniciales de la capa mediante el parámetro *weights*. Además, nos permite especificar si queremos modificar los pesos en nuestro propio entrenamiento o no.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5celap27Yy_2",
        "colab_type": "code",
        "outputId": "885df002-8392-4d03-b01e-1a32096f4396",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Embedding\n",
        "import numpy as np\n",
        "\n",
        "# Definimos el tamaño del vocabulario y las dimensiones del espacio latente\n",
        "vocabulary_size = 5\n",
        "embedding_space = 3\n",
        "\n",
        "# Creamos una matriz de embedding aleatoria\n",
        "embedding_matrix = np.random.rand(vocabulary_size,embedding_space)\n",
        "\n",
        "print('Tabla de embedding inicial')\n",
        "for idx, representation in enumerate(embedding_matrix):\n",
        "  print(idx,representation)\n",
        "\n",
        "# Definimos una entrada de longitud variable\n",
        "input_layer = Input(shape=(None,), dtype='int32', name='main_input')\n",
        "\n",
        "# Proporcionamos la matriz anterior como parámetro\n",
        "embedding = Embedding(vocabulary_size, embedding_space,\n",
        "                            weights=[embedding_matrix],\n",
        "                            trainable=True)(input_layer)\n",
        "\n",
        "# Creamos el modelo de embedding\n",
        "model = Model(input_layer,embedding)\n",
        "\n",
        "# Comprobamos el embedding sobre este modelo \n",
        "integer_encoding = [4,1,3,3,3]\n",
        "output_array = model.predict(np.asarray([integer_encoding]))\n",
        "\n",
        "print('')\n",
        "print('Representación de: ' + str(integer_encoding))\n",
        "print(output_array)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tabla de embedding inicial\n",
            "0 [0.78987165 0.02071891 0.44158715]\n",
            "1 [0.51946222 0.92426688 0.92094709]\n",
            "2 [0.57110801 0.49882486 0.68064374]\n",
            "3 [0.22824449 0.33314266 0.09556879]\n",
            "4 [0.36113611 0.48007591 0.0550137 ]\n",
            "\n",
            "Representación de: [4, 1, 3, 3, 3]\n",
            "[[[0.3611361  0.4800759  0.0550137 ]\n",
            "  [0.5194622  0.9242669  0.9209471 ]\n",
            "  [0.22824448 0.33314267 0.09556879]\n",
            "  [0.22824448 0.33314267 0.09556879]\n",
            "  [0.22824448 0.33314267 0.09556879]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4Xizk8eYyKl",
        "colab_type": "text"
      },
      "source": [
        "Aunque la forma de importar la matriz de embedding no está oficialmente documentada en la página web de Keras, se puede acceder a un tutorial completo:\n",
        "\n",
        "[Importando pesos pre-entrenados a una capa de Embedding](https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFE8wTSLE_At",
        "colab_type": "text"
      },
      "source": [
        "## Modelo de atención\n",
        "\n",
        "A menudo, la etapa de codificación es muy compleja, especialmente cuando la secuencia de entrada es muy larga. Es por ello que el context vector es insuficiente para capturar la información necesaria para toda la etapa de decodificación. Para paliar este fenómeno, se utilizan los **modelos de atención**.\n",
        "\n",
        "Un modelo de atención es una estructura neuronal que complementa el enfoque secuencia a secuencia. En cada paso de decodificación, el modelo de atención asigna un peso a cada uno de los elementos de la etapa de codificación; es decir, ayuda a saber en qué parte de la entrada debe el decodificador *poner su atención* en cada paso:\n",
        "\n",
        "![texto alternativo](https://github.com/tensorflow/nmt/raw/master/nmt/g3doc/img/attention_mechanism.jpg)\n",
        "\n",
        "Como subproducto de este proceso, el modelo aprende de manera suavizada tanto la tarea en sí como el alineamiento subyacente:\n",
        "\n",
        "![texto alternativo](https://github.com/tensorflow/nmt/raw/master/nmt/g3doc/img/attention_vis.jpg)\n",
        "\n",
        "Los modelos de atención representan el estado del arte en las tareas de secuencia a secuencia implementadas con un enfoque encoder-decoder, y son imprescindibles para construir exitosamente modelos neuronales para problemas complejos como la traducción automática.\n",
        "\n",
        "### Modelo de atención en Keras\n",
        "\n",
        "Actualmente, Keras no incorpora modelos de atención en sus implementaciones base. Para poder utilizar este tipo de esquemas, hay que hacerlo combinando los elementos que Keras sí incorpora.\n",
        "* [Tutorial para incorporar atención en Keras](https://wanasit.github.io/attention-based-sequence-to-sequence-in-keras.html)"
      ]
    }
  ]
}